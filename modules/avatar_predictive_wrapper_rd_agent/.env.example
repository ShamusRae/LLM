# Server Configuration
PORT=3000

# RD-Agent Python Path
PYTHON_PATH=/usr/bin/python3
RD_AGENT_PATH=./python/rd-agent

# Task Configuration
DEFAULT_DOMAIN=general
DEFAULT_TASK_TYPE=classification

# LLM API Configuration
# Copy these values from your main LLM Chat backend/.env file
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
COHERE_API_KEY=your_cohere_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here

# Ollama Configuration
OLLAMA_API_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# Optional: Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint_here

# Optional: Additional Provider Keys
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Logging
LOG_LEVEL=info 